# ADR-0003: Data quality gates and fail-fast enforcement at the Silver boundary

**Status:** Proposed  
**Date:** 2026-01-31  
**Owners:** Data Platform (Project)  
**Decision Drivers:** reliability, fail-fast pipelines, trustworthy Silver boundary, auditability, backfill safety, training-serving skew prevention

## Context

ADR-0001 establishes Delta Lake tables with layer-specific write semantics: Bronze is append-only raw truth, Silver allows merges for idempotency, and Gold writes PIT-correct feature snapshots. ADR-0002 introduces enforceable data contracts and schema versioning to prevent silent schema drift.

To make Silver truly “trusted,” we need **data quality gates** that run consistently on every Silver write. Without quality enforcement:

- Silver merges can preserve or amplify bad data (null keys, duplicates, invalid timestamps).
- Downstream feature engineering can silently compute incorrect churn features (leakage, missing events, skew).
- Reruns and backfills can introduce regressions without detection.

We need a production-style quality framework that is **aligned with Silver MERGE semantics**: validate, fail-fast when critical constraints break, and quarantine/measure non-critical issues.

## Decision

1. **Implement standardized data quality gates for all Silver writes** as part of the write path (before commit).
2. **Classify checks into tiers** with deterministic outcomes:
   - **Critical (Blocker):** fail the job; do not write/merge.
   - **Warn:** write allowed; emit metrics + record failures.
   - **Quarantine:** route failing records to a quarantine table; write clean subset.
3. **Bind quality rules to table contracts** (ADR-0002) so checks are discoverable, versioned, and reviewable.
4. **Record quality results** for every run to support reliability targets and debugging.

## Quality gate scope by layer

### Bronze

- Bronze is raw fidelity. Quality checks are informational only (profiling/metrics).
- No job should fail solely due to Bronze data shape/content unless ingestion is structurally broken (e.g., unreadable files).

### Silver (enforced)

- Silver is the enforcement boundary.
- All Silver write jobs must run gates and adhere to pass/fail outcomes.

### Gold

- Gold relies on Silver correctness; Gold checks focus on feature completeness and snapshot integrity.
- Gold checks should be strict for schema/keys and warn-level for distribution shifts (unless explicitly required).

## Check tiers and outcomes

### Tier 1 — Critical (Blocker)

If any Tier 1 check fails:
- **Fail fast**
- **Do not commit** the Silver table write/merge
- Persist a quality report for triage

Examples (typical Silver tables):
- Primary keys are null (e.g., `order_id`, `customer_id`)
- Duplicate keys within the batch (or post-merge uniqueness violation)
- Required timestamps are null/invalid (e.g., `order_purchase_ts`)
- Contract schema mismatch (enforced by ADR-0002)

### Tier 2 — Warn (Non-blocking)

Write proceeds, but:
- emit metrics
- record failures in a quality results table
- optionally alert in CI/logs

Examples:
- Unexpected null rates in non-key columns
- Out-of-range numeric values (e.g., negative payment amounts)
- Unexpected enum values where a fallback mapping exists

### Tier 3 — Quarantine (Split write)

Failing records are separated:
- Write the passing subset to Silver
- Write failing subset to `silver.quarantine.<table>` with failure reasons

Examples:
- Records missing optional join keys needed for some features
- Rows with malformed fields that can’t be safely coerced but shouldn’t block the entire run

## Alignment with Silver write semantics (MERGE)

Silver uses `MERGE INTO` for idempotency. Quality gates must therefore validate:

1. **Pre-merge batch validity**
   - keys non-null
   - schema conforms to contract
   - dedupe resolution produces at most one row per merge key in the batch

2. **Merge correctness**
   - the merge condition matches the contract primary keys
   - merge does not introduce duplicate keys in the target

3. **Post-merge invariants**
   - uniqueness checks on primary keys (table-level)
   - row counts and null rates within expected bounds (warn-tier)

This ensures “rerun safety”: a rerun cannot silently degrade Silver.

## Standard checks (baseline)

All Silver tables must implement at minimum:

### Schema + contract checks (Critical)
- Required columns present
- Types match contract
- Nullability adheres to contract (contract is upper bound)

### Key integrity (Critical)
- Primary keys non-null
- No duplicate primary keys after dedupe logic
- Merge keys match contract `primary_keys`

### Timestamp sanity (Critical/Warn)
- Required event timestamps non-null (Critical if used in downstream windows)
- Event timestamps within plausible range (Warn unless it breaks joins/windows)

### Domain constraints (Warn/Quarantine)
- Known enums (e.g., status fields) within allowed set
- Numeric ranges (non-negative amounts, quantities)
- Referential integrity sampling (Warn): e.g., `order_items.order_id` should exist in `orders.order_id`

## Quality specification location

Quality rules are stored alongside contracts in the repo:

```

contracts/
silver/<domain>/<table>.yaml
gold/<domain>/<table>.yaml

```

Each contract includes a `quality` section:

- `critical_checks`: list
- `warn_checks`: list
- `quarantine_checks`: list
- `dedupe`: precedence rules (e.g., keep latest by `_ingest_ts` or event time)

This keeps quality policy versioned and reviewable with schema changes.

## Options considered

### Option A — Contract-driven quality gates (Chosen)

**Pros**
- Consistent across all tables; easy to scale to more tables.
- Reviewable and enforceable via Git/CI.
- Naturally aligned with Silver merge semantics and ADR-0002 contracts.

**Cons**
- Requires upfront definition of checks per table.
- Needs disciplined ownership to avoid “check sprawl.”

### Option B — Ad hoc checks inside each Spark job

**Pros**
- Fast to start.

**Cons**
- Inconsistent outcomes and reporting.
- Hard to audit; rules drift across jobs.
- Difficult to enforce in CI.

### Option C — Only monitor quality (no blocking gates) (Rejected)

**Pros**
- No pipeline interruptions.

**Cons**
- Bad data propagates to Gold and model training.
- Violates “trusted Silver boundary” requirement and increases skew risk.

## Consequences

### Positive

- Silver becomes measurably trustworthy with deterministic enforcement.
- Fail-fast behavior prevents bad merges and corrupted trusted tables.
- Quality results provide audit trails and speed up debugging/backfills.
- Downstream churn features and serving outputs are more stable and reproducible.

### Negative / Risks

- Strict critical gates can fail runs during source anomalies; requires clear triage workflow.
- Quarantine logic adds operational complexity and requires monitoring.
- Poorly tuned thresholds can create noise (warn fatigue).

## Implementation notes

### Quality engine

Add a small quality module:

- `src/common/quality/`
  - `run_quality(df, contract) -> QualityReport`
  - `apply_quarantine(df, report) -> (df_pass, df_fail)`
  - `assert_critical(report) -> None`

### Reporting tables

Write run results to a small, queryable Delta table (or PostgreSQL if preferred):

- `silver.meta.quality_results`
  - `run_id`, `table_id`, `schema_version`, `as_of_date` (if relevant), `status`
  - check name, tier, failures count, sample keys, timestamps

And quarantine tables per entity:

- `silver.quarantine.<domain>_<table>`
  - original row + `_failure_reasons`, `_quarantine_ts`, `run_id`

### Where checks run

- **Silver:** gates run immediately before `MERGE INTO` and optionally after merge for table-level invariants.
- **Gold:** basic schema/key checks run before writing snapshots; warn-tier distribution checks are optional and recorded.

### Metrics

Emit operational metrics per run:
- critical constraint pass rate
- warn counts by check
- quarantine row counts
- run success/failure

These map directly to the project’s reliability targets.

## Acceptance criteria

This ADR is “done” when:

1. A Silver run with null primary keys fails before commit and writes a quality report.
2. A Silver run with malformed non-critical rows can quarantine those rows and still write a clean Silver output.
3. Quality results are persisted per run and can be queried to compute:
   - critical pass rate (target >= 99%)
   - scheduled run success rate (target >= 95%)

## Follow-ups

- Add CI tests for quality rules: synthetic bad inputs should deterministically fail/pass as expected.
- Add a small “quality dashboard” query/view (even a SQL report) for `quality_results` and quarantine volumes.
- Define Gold-level distribution checks (drift) once the baseline feature set is stable.
